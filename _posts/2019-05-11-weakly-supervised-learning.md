---
layout: post
title: "关于弱监督学习"
description: ""
category:
tags:
---

本文部分参照周志华的文章，其他为个人思考和总结。

> 周志华的弱监督学习简述：https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/nsr18.pdf

## 引言

最理想的情况就是有数据用于监督训练和评估模型，有完整的数据闭环，工程师只需要关注算法和模型迭代。

- 有监督/强监督：数据集中每一项包括实例（instance X）和标签（label Y）两部分。标签是待解决的任务的 ground truth。

但是现实中常常难以获取理想的全量数据的 ground truth 标签。缺乏标注的原因可能是标注的人工成本太高（例如图像分类，需要人工打标签），也可能是标注具有现实困难（例如贷款是否违约，无法由人工进行标注）。

- 不完整监督：数据只有一部分有标签，其他数据未标注。
- 不确切监督：标签粒度较粗，标注目标与待解决任务并不完全一致。
- 不准确监督：标签有一部分是错误的。
- 无监督：数据无任何标注。

前三种情况属于弱监督。

此外，还有一种分类方式：

- 如果测试数据也算是未标注训练数据，称为 transductive learning，有人翻译为直推学习。
- 如果测试数据不能提前使用，称为 inductive learning，这也是一般的情况。

现实中可能会出现多种情况的混合，例如标签粒度较粗，并且有一部分错误，并且还有一部分数据未标注。而且值得注意的是，数据条件和学习范式并不一定是一一对应的。

举一个我比较熟悉的例子，目标是获取海量英语单词的法语翻译，换句话说，把英语、法语按照词汇级别对齐：

- 如果我们标注了一部分英语单词的法语翻译，其他单词未标注，属于不完整监督，如果没有其他语料或数据，我认为这实际导致任务不可能完成。
- 如果有句子级别的双语对齐语料，就属于不确切监督，标签是句子粒度的，不是我们期望的单词粒度的。
- 如果有句子级别的双语对齐语料，采用一个加强的不准确的假设，即法语句子中的每个词都是英语句子中的每个词的上下文可能翻译，然后采取 word2vec skip-gram 框架，用英语句中的词预测法语句中的共现词，就转化为不准确监督。
- 如果只有英语和法语各自的单语语料，完全没有对齐信息，就属于无监督，可能要利用词频分布、词向量空间结构等信息，按照某些假设训练，例如假设同一概念的词在不同语言中词频排序大致相同，或者不同语言的词向量空间存在同构映射。
- 实践中，一般是有小规模的词级别双语对齐语料（人工标注的词典），小规模的句子级别双语对齐语料（机器翻译语料），大规模的单语语料，因此需要结合上述不同学习场景；事实上，上面每个场景都有相关的研究工作。

下面对弱监督的三种情形分别介绍，参考周志华的文章。

## 不完整监督

数据只有一部分有 ground truth 标签，其他数据未标注。学习要点在于如何利用未标注数据。

取决于是否有条件（例如询问标注员）获得未标注数据的 ground truth 标签，主要有两种解决方法：主动学习，半监督学习。

主动学习有条件询问新的标注，目标是以最小的标注成本（询问次数或询问样本数）获得好的模型，关键是设计某种标准用来选取最值得标注的样本，常用的标准是信息量（informativeness）和代表性（representativeness）：

- 信息量：标注一个样本对于模型不确定性的降低程度
    - 不确定性采样（uncertainty sampling），训练一个学习器，对未标注数据做预测，选出最没把握的样本用于询问标注；
    - 不一致投票查询（query-by-committee），训练几个学习器，对未标注数据做预测，选出最不一致的样本用于询问标注。
- 代表性：一个样本对于输入模式结构的有效表示程度
    - 聚类，比如说选取最靠近簇中心的样本。

半监督学习不涉及额外标注，关键是挖掘并利用未标注数据的分布。主要的假设是数据具有簇结构（cluster）或者分布于流形上（manifold），空间距离近或结构类似的样本具有相近的标签。常用的方法有四类：

- 生成方法：假设有标注、无标注实例都是从同一个模型生成的（需要领域知识来确定先验），可以认为缺失了部分标签（即参数），因此可以用 EM 算法估计；
- 基于图的方法：顶点是训练实例，边是实例之间的关系（相似度或距离），标签根据某种规则在图上传播，这种方法训练速度很慢，而且测试数据也需要加到图中（直推学习）；
- 低密度分隔的方法：分类边界必须位于样本空间中较为稀疏的区域，例如从 SVM 推广来的 S3VM；
- 基于不一致性的方法：多个学习器合作利用未标注数据，例如将预测结果作为伪标注，又如 co-training。

总的来说，主动学习的思路是直接训练学习器，选出最没把握的样本，确认它的标注；半监督学习的思路是从确定的样本出发，将标签扩散到其他不确定的样本。在这个过程中，半监督学习可能反而导致过拟合加重，因此建议采用 ensemble 等方式避免最坏情况。

顺便指出，基于不一致性的方法对于不完整监督学习是非常重要的，但相关研究其实早于近年的机器学习热潮，因此很多相关论文并没有采用主动学习、半监督学习之类的关键词。

## 不确切监督

标签粒度较粗，与待解决任务并不完全一致。学习要点在于如何使标签为目标任务提供监督信息。

例如物体检测任务，只有图像级别的分类，没有物体级别的标签

现在，不确切监督一般指的是多示例学习（multiple instance learning）：训练数据不知道每个实例的标签，只知道一组实例（称为一个 bag）中是否有正例，任务是预测新的一组实例是否有正例（或者识别哪个实例）。最初提出的背景是药物活性预测，同一个分子可能具有不同的空间构型（都是能量较低的状态），其中只有一种或几种有活性，目标是预测一个分子是否有某种构型有活性，而无需对每种构型进行分离和检测。此时，一个分子构成一个 bag，其中的实例是它的不同构型。再例如，一张图像或一个文档构成一个 bag，其中的实例是提取的特征，这种情形在图像场景分类和文本分类中非常常见。

如果采用直接预测 bag 的目标函数，一个包含大量负例的正 bag 很容易造成干扰。所以有的算法尝试更进一步，对所有实例进行预测，第 $i$ 个 bag 的第 $j$ 个实例标签为正的概率为 $P_{ij}$，那么这个 bag 标签为正的概率为“所有实例标签的逻辑 OR 为正的概率”，即 $1 - \prod_j (1- P_{ij})$，于是设计成一个适用于多实例学习的目标函数。（这里省略了一部分贝叶斯公式变换、均匀分布先验以及独立分布假设。）

我认为，另一类情形其实也属于不确切监督，尽管文献很少会如此描述。例如只知道一张图片中是否有车，任务是给出车的边框；贷款申请之类的回归预测也具有一点不确切监督的味道，只知道某客户某次申请五百万贷款后是否违约之类的数据，任务是预测其他条件下批贷其他金额时的违约概率。

总的来说，不确切监督可能引入一个隐藏的过程，修改目标函数使一种任务的标注数据适用于另一种任务的目标，模型也需要具备泛化能力好、抗干扰、能够综合概括信息的性质。

## 不准确监督

标签有一部分是错误的，例如标注者失误或者某个样本本身难以归类。

总的来说，不准确监督通常提供的信息量比前两者更多。需要注意的是，像 SVM 还有一些 boosting 模型会给不同的样本不同的权重，过分依赖于关键样本，更容易受到错误标注干扰。反之，如果给所有的样本相同的权重，那么使用常规算法通常也能取得一定效果。更进一步，专门针对不准确监督的场景，可以尝试识别疑似错误标注，降低它们的权重。

例如，通过训练一个常规模型之后的错误分析，人工移除错误标注的点。同样的思路，也可以对噪声建模，移除可疑的点。

如果是众包引入的标注者失误或标注不一致，可以对标注者建模，给予不同的信任权重；或采用 ensemble 方式，试图投票推断出 ground truth。

总的来说，其实很多比赛和业界项目中，大家已经在自发地针对不准确标注进行相应的处理，因为不准确标注是普遍存在的。但我认为，不准确监督学习的重要性并不在于如何减少错误标注带来的干扰，而在于如何将无监督场景转化为不准确监督场景，从而使无监督问题可以学习。

## 无监督

“纯粹”的无监督情况下，只能按照某种先验或者偏好训练模型。例如我们可以通过统计字的共现信息实现无监督分词，但是这里利用了人的领域知识和主观知识作为监督信息，例如为何选择计算互信息，如何挑选阈值，如何判断分词效果。

对于更加“端到端”的无监督，一种常见的策略是“加强监督”（这是我自创的命名，暂时不知道它的通行命名）：采纳某种粗犷的假设，将无监督问题转化为不准确监督。

例如本文一开始举例介绍过的词向量问题。很多无监督词向量训练，实际上是把无标注语料库中的词语是否上下文共现作为监督信息，从而使无监督学习转化为有弱监督的共现预测问题，例如 word2vec、bert 在内的语言模型大多数都是基于类似的假设。

再比如知识图谱关系抽取中的远程监督方法，同样是假设两个实体共现的句子能刻画两个实体之间的关系，这也是不准确监督信息，但它减少了模型对标注数据的依赖。这种“加强监督”策略的固有缺点就是噪声大，错误标注多，但是采用适当的目标函数和训练框架，它完全可以用来解决对个别特例不太敏感、拥有海量语料的问题。

回顾机器学习、深度学习领域，以往理论到业界实践之间的最大鸿沟就在于数据条件。可喜的是，近年来越来越多的人开始关注迁移学习，少量样本的学习（zero-shot/one-shot/few-shot learning），以及无监督或弱监督的学习。这也对研究者的信息论、统计学基础提出了更高的要求。
